# -*- coding: utf-8 -*-
"""SER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JUpYFOsnnVVGnyRmjCHfM4bTWWiWlV9T
"""

import numpy as np
import pandas as pd
import os
import librosa
import wave
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

import keras
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import *
from keras.optimizers import RMSprop

print("loaded libraries")

from google.colab import drive
drive.mount('/content/drive')

def extract_mfcc(wav_file_name):
  y,sr = librosa.load(wav_file_name)
  mfcc=np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)
  return mfcc

radvess_speech_labels=[]
ravdess_speech_data=[]
for dirname, _,filenames in os.walk('/content/drive/MyDrive/archive'):
  for filename in filenames:
    radvess_speech_labels.append(int(filename[7:8])-1)
    wav_file_name=os.path.join(dirname,filename)
    ravdess_speech_data.append(extract_mfcc(wav_file_name))

print("finish loading the dataset")

ravdess_speech_data

ravdess_speech_data_array=np.array(ravdess_speech_data)
ravdess_speech_label_array=np.array(radvess_speech_labels)
ravdess_speech_label_array.shape

labels_categorical=to_categorical(ravdess_speech_label_array)
labels_categorical.shape

ravdess_speech_data_array

x_train,x_test,y_train,y_test=train_test_split(np.array(ravdess_speech_data_array),labels_categorical,test_size=0.20,random_state=9)

number_of_samples=ravdess_speech_data_array.shape[0]
training_samples=int(number_of_samples * 0.8)
validation_samples=int(number_of_samples * 0.1)
test_samples=int(number_of_samples * 0.1)

def create_model_LSTM():
  model=Sequential()
  model.add(LSTM(128, return_sequences=False, input_shape=(40,1)))
  model.add(Dense(64))
  model.add(Dropout(0.4))
  model.add(Activation('relu'))
  model.add(Dense(32))
  model.add(Dropout(0.4))
  model.add(Activation('relu'))
  model.add(Dense(8))
  model.add(Activation('softmax'))

  model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])
  return model

w=np.expand_dims(ravdess_speech_data_array[:training_samples], -1)

w.shape

model_A=create_model_LSTM()
history=model_A.fit(np.expand_dims(ravdess_speech_data_array[:training_samples],-1),labels_categorical[:training_samples],validation_data=(np.expand_dims(ravdess_speech_data_array[training_samples:training_samples+validation_samples], -1),labels_categorical[training_samples:training_samples+validation_samples]),epochs=130,shuffle=True)

loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1,len(loss)+1)
plt.plot(epochs,loss,'ro',label='Training loss')
plt.plot(epochs,val_loss,'b',label='validation loss')
plt.title('training and validation loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']

plt.plot(epochs,acc,'ro',label="training accuracy")
plt.plot(epochs,acc,'b',label="validation accuracy")
plt.title('training and validation accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()

plt.show()

model_A.evaluate(np.expand_dims(ravdess_speech_data_array[training_samples + validation_samples:], -1), labels_categorical[training_samples + validation_samples:])

emotions={1: 'neutral',2: 'calm',3: 'happy',4: 'sad',5: 'angry',6: 'fearful',7: 'disgust',8: 'surprised'}
def predict(wav_filepath):
    test_point = extract_mfcc(wav_filepath)
    test_point = np.reshape(test_point, (1, 40))
    predictions = model_A.predict(test_point)
    print(emotions[np.argmax(predictions[0])+1])

predict('/content/drive/MyDrive/archive/Actor_01/03-01-01-01-01-01-01.wav')

predict('/content/drive/MyDrive/archive/Actor_01/03-01-03-01-01-02-01.wav')

predict('/content/drive/MyDrive/archive/Actor_03/03-01-02-02-01-01-03.wav')

model_A.save('/content/drive/MyDrive/SER_model.h5')

import h5py
import tensorflow as tf

# Path to your saved Keras model (.h5 file)
model_path = '/content/drive/MyDrive/SER_model.h5'

# Open the .h5 file using h5py
with h5py.File(model_path, 'r') as f:
    # Check the TensorFlow and Keras version attributes
    if 'keras_version' in f.attrs:
        print('Keras version used to save the model:', f.attrs['keras_version'])
    else:
        print('Keras version attribute not found in the model file.')

    if 'tensorflow_version' in f.attrs:
        print('TensorFlow version used to save the model:', f.attrs['tensorflow_version'])
    else:
        print('TensorFlow version attribute not found in the model file.')

